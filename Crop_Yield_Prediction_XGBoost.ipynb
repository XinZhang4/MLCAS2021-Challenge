{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e80b65d",
   "metadata": {},
   "source": [
    "## Crop Yield Prediction using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af09d5",
   "metadata": {},
   "source": [
    "### Importing the Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edee7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7c6ac",
   "metadata": {},
   "source": [
    "### Loading the numpy binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f4dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data load\n",
    "weather_data = np.load('inputs_weather_train.npy', allow_pickle=False, fix_imports=True)\n",
    "other_data = np.load('inputs_others_train.npy', allow_pickle=False, fix_imports=True)\n",
    "yield_data = np.load('yield_train.npy', fix_imports=True, allow_pickle=False)\n",
    "clusterID_genotype = np.load('clusterID_genotype.npy', fix_imports=True, allow_pickle=False)\n",
    "\n",
    "weather_test_data = np.load('inputs_weather_test.npy', allow_pickle=False, fix_imports=True)\n",
    "other_test_data = np.load('inputs_others_test.npy', allow_pickle=False, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb22b23",
   "metadata": {},
   "source": [
    "### Scaling and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39376510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "other_data[:, 2] = encoder.fit_transform(other_data[:, 2].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[length, days, prop_num] = weather_data.shape \n",
    "\n",
    "# main data part\n",
    "weather_data1 = np.zeros([length, int(days/7), prop_num])\n",
    "\n",
    "# sum up year data by week\n",
    "for i in range(length):\n",
    "    year_data = weather_data[i]\n",
    "    year_data1 = year_data[0:int(days/7)*7, :]\n",
    "    year_data2 = year_data1.reshape(int(days/7),7,7)\n",
    "    year_by_week = year_data2.sum(axis=1)\n",
    "    weather_data1[i] = year_by_week\n",
    "\n",
    "weather_data3 = weather_data1.reshape(length, 7 * int(days/7))\n",
    "weather_df = pd.DataFrame(weather_data3)\n",
    "other_df = pd.DataFrame(other_data, columns=['MG', 'Genotype_ID', 'State', 'Year', 'Location'])\n",
    "yield_df = pd.DataFrame(yield_data, columns=['Yield'])\n",
    "\n",
    "# Combining the entire dataset \n",
    "combined_df = pd.concat([weather_df, other_df, yield_df], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8d5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = combined_df['State'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa536c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '0', '25', ..., '6', '9', '3'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6570c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.iloc[:,0:-1].values # selects everything except label and assign to X\n",
    "Y_real = combined_df.iloc[:, -1].values # selects yield data part and assign to Y_real\n",
    "max_val = np.max(Y_real)     # maximum value of Y_real \n",
    "Y = Y_real/max_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7686c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "X = np.asarray(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca75b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, -3] = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9797cd",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train_test. Ratio 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df62627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset to training and testing, ratio 9:1\n",
    "training_size = int(len(X) * 0.90)\n",
    "test_size = len(X) - training_size\n",
    "X_train, X_test = X[0:training_size], X[training_size:len(X)]\n",
    "Y_train, Y_test = Y[0:training_size], Y[training_size:len(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79af4b",
   "metadata": {},
   "source": [
    "### GridSearch CV for hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42098846",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GridSearch CV for hyper-parameter-tuning.\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "             'max_depth': [8, 9],\n",
    "             'n_estimators':[800,1000],\n",
    "             'subsample': [0.6,0.7],\n",
    "             'colsample_bytree': [0.8,0.9]}\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"r2\", n_jobs=-1)\n",
    "grid_result = grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_param_))\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0271a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE 6.242293070203708\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(n_estimators=1500, max_depth=8, eta=0.1, subsample=1.0, colsample_bytree=0.8,\n",
    "                 min_child_weight=7, reg_alpha=0.01)\n",
    "\n",
    "xgb.fit(X_train, Y_train)\n",
    "test_predict=xgb.predict(X_test)\n",
    "trainScore = np.sqrt(mean_squared_error(Y_test *max_val, test_predict*max_val))\n",
    "print ('Training RMSE', trainScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cdedf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, enable_categorical=False,\n",
       "             eta=0.1, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.100000001,\n",
       "             max_delta_step=0, max_depth=8, min_child_weight=7, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1500, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, subsample=1.0,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40611a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "[length_test, days_test, prop_num_test] = weather_test_data.shape\n",
    "\n",
    "weather_test_data1 = np.zeros([length_test, int(days_test/7), prop_num_test])\n",
    "\n",
    "for i in range(length_test):\n",
    "    year_data = weather_test_data[i]\n",
    "    year_data1 = year_data[0:int(days/7)*7, :]\n",
    "    year_data2 = year_data1.reshape(30,7, prop_num_test)\n",
    "    year_by_week = year_data2.sum(axis=1)\n",
    "    weather_test_data1[i] = year_by_week\n",
    "\n",
    "\n",
    "weather_data3 = weather_test_data1.reshape(length_test, prop_num_test * int(days/7))\n",
    "weather_test_df = pd.DataFrame(weather_data3)\n",
    "\n",
    "other_test_df = pd.DataFrame(other_test_data, columns=['MG', 'Genotype_ID', 'State', 'Year', 'Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8edaf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MG</th>\n",
       "      <th>Genotype_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>\"IA\"</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>\"IN\"</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>\"IA\"</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>\"MD\"</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>\"IL\"</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10332</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4511.0</td>\n",
       "      <td>\"MI\"</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10333</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5106.0</td>\n",
       "      <td>\"NE\"</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10334</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5826.0</td>\n",
       "      <td>\"IL\"</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5466.0</td>\n",
       "      <td>\"SD\"</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3685.0</td>\n",
       "      <td>\"ND\"</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10337 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MG Genotype_ID State    Year Location\n",
       "0      3.0      3069.0  \"IA\"  2010.0     41.0\n",
       "1      4.0      2526.0  \"IN\"  2004.0    154.0\n",
       "2      3.0       636.0  \"IA\"  2014.0     41.0\n",
       "3      5.0      1350.0  \"MD\"  2005.0    113.0\n",
       "4      3.0      2983.0  \"IL\"  2006.0    148.0\n",
       "...    ...         ...   ...     ...      ...\n",
       "10332  1.0      4511.0  \"MI\"  2013.0     64.0\n",
       "10333  3.0      5106.0  \"NE\"  2007.0    136.0\n",
       "10334  2.0      5826.0  \"IL\"  2008.0    148.0\n",
       "10335  1.0      5466.0  \"SD\"  2005.0     10.0\n",
       "10336  0.0      3685.0  \"ND\"  2013.0     31.0\n",
       "\n",
       "[10337 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f648d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_test_df[\"State\"] = encoder.transform(other_test_df[\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89e4515b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6,  4, ...,  5, 24, 17])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_states = other_test_df[\"State\"].values\n",
    "test_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd51ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10337"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a64b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_df = pd.concat([weather_test_df, other_test_df], axis = 1, join = 'inner')\n",
    "X_test = combined_test_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac49ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10337"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b86151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "426c7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:, -3] = test_states\n",
    "# X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "test_predict=xgb.predict(X_test)*max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a4e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test_predict-Final_best.npy\",  test_predict)  # save the new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
